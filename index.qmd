---
title: "Memo: Swing States Project and Estimating PID"
date: "Aug. 22, 2023"
bibliography: "sept23-memo.bib"
format:
    html:
        toc: true
        number-sections: true
        toc-depth: 7
        toc_float:
            collapsed: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(tidyverse)
library(knitr)
```

Several decisions regarding methods and data remain to be made for the swing states project. This memo outlines the current state of the project and the decisions that need to be made. The main remaining issue is determining what geographic level we can feasibly use in poststratification to then aggregate to state-level estimates of partisanship.

# Project Overview

**Research question:** Why does a state become a swing state, or, why do states swing in presidential elections?

- Intuition that elite polarization is a driver of swinginess
- Are we interested in framing our question in terms of swings being a temporary status or a durable trait of some states, or both?

**Level of analysis:** the 48 contiguous states ($i$) in presidential elections ($t$) from 1996[^1] to 2020.

[^1]: The @shor2022Two elite polarization data goes back to 1996, setting a lower bound for our time-series.

**Main Hypotheses (Rough)**

1. As a given state's legislative branch becomes more polarized, the state is more likely to swing in presidential elections.

**Competing Hypotheses -- Partisanship**

2. As the proportion of a state's voters identifying as true independents increases, the state is more likely to swing in presidential elections. 
3. As a state's two-party make-up shifts towards equal proportions for both parties, the state is more likely to swing in presidential elections.

**Causal Drivers:**

- elite polarization
- Partisan realignment: migration, birth rates, attitude shifts

# Estimating Partisan Identification at the State Level

This project requires a robust partisanship covariate at the state level. Samara and Reed have been discussing this problem since the Spring, and have come up with a plan to collect estimates for the proportion of Democrats, Republicans, and Independents in each state for each year of the analysis. Because our hypothesis concerns vote choice, using data that contain measures for partisan leaning independents is a priority [@keith1986Partisan]. We have not been able to find this type of partisanship estimate in the existing literature. This section outlines a tentative plan and the available data. 

We will estimate our state-level partisanship variable using Multilevel Regression and Poststratification (MRP) within a Bayesian framework [see @pacheco2011Using, @gelmanChapter, @goplerud2023ReEvaluating, @buttice2013How]. To perform MRP, we need two types of data: demographic population data, and polling data. The polling data is used to fit a multinomial logistic model that estimates the individual-level probability of a given respondent identifying as a Democrat, Republican, or Independent. The administrative data is then used to create a poststratification frame, which is essentially a joint distribution of individual-level demographics that are parsed out by geographic unit(s) such as counties or states.[^2] Each row of this distribution can be thought of as a demographic profile that exists in the population for a given geography. Next, the model trained on polling data is used to predicted the probability of each profile belonging to each of the three parties. The frequencies of the profiles in the geographic level of interest can then be used to predict weighted probabilities of each profile identifying as a Democrat, Republican, or Independent which can then be aggregated to any geographic level present in the polling and demographic data to obtain partisan proportions.

[^2]: We will likely include region, state, and county or census tract predictors in our model, which means that estimates for missing counties can be imputed using state and regional information the same way region can inform estimates for states that were not polled in a given year.

This approach aligns well with our broader project's goals for a few reasons. Most importantly, the multilevel model allows for information to be pooled across the levels of the variables, which is especially useful when estimating states with small sample sizes. The multilevel model also allows us to make reasonable predictions of partisan identification for geographies that were not sampled in the available polling data for one or more years of interest. This is because in a multilevel framework we compute means at every level of analysis, which allows us to incorporate information about a state's region and other characteristics in our estimates.[^3]

[^3]: The weighting process is greatly improved by the inclusion of state-level predictors, such as the state's region, previous electoral returns, and so on. These are included in the model as fixed effects, and must also be included in the poststratification frames in order for predictions to be possible.

The above explanation is the standard MRP implementation for estimating state-level opinion for a single year. Because we are interested in generating partisanship estimates for several years, some modifications to the above framework are necessary. Luckily, the longitudinal nature of our question can be used to our advantage when it comes to generating optimal partisanship estimates. If we combine all available polling data across years into a single dataset and estimate the model with varying year intercepts then information will also be shared between years for the given geographies used, which will provide additional robustness to our estimates. 

An important obstacle for estimating state-level partisanship is that the available polling data is usually  sampled using area clustering, which means that they are likely not representative of the individual state populations being studied. In many recent years, the American National Election Study has used simple random sampling to obtain a portion of its overall sample, which mitigates this issue to an extent. However, it has been proposed that the problem could be further addressed by accounting for the sampling design of area-clustered samples in the predictive model itself (@stollwerkEssays).[^4] This is achieved by including random effects for the geographic units that were used in area clustered sampling during survey sampling. The resulting partial pooling of information across geographies smaller than the state will improve all of our estimates because it will provide information about a state that would be otherwise missing for any given year by borrowing means generated within that state from other years during prediction. The extent to which this approach can be implemented depends upon the available polling and demographic data.

[^4]: @stollwerkEssays was not able to implement this approach due to data restrictions, however, even without directly incorporating the sampling design of the polls, they were able to improve their estimates by including random effects for Congressional districts.

# Available Data

## Polling Data

Because our main and perhaps only consistent source of polling data is the ANES data, it would be helpful to  bolster the years of the ANES time-series that have smaller smaller samples by combining them with other polls. This section discusses the available polling data and its limitations.

## Existing Estimates

@pacheco2014Measuring provides poll-based estimates for the proportion of Democrat identifiers out of all partisans (Republicans Democrats, and Independents) for 1978 to 2010. These estimates are primarily based on CBS/NYT polls. They utilize an older and less accurate approach to MRP that does not utilize multiple deep interactions when specifying the multilevel model (called "deep MRP") [see @goplerud2023ReEvaluating], and they don't account for the sampling design of the polls [@auslen2023Improving; @stollwerkEssays], making them of limited use for our purposes.

## Cooperative Congressional Election Study

- Large sample size and an approximately simple random sample make it very reliable 
    - MRP provides little improvement over simple mean estimates of state level public opinion [@gelmanChapter]
    - only available for 2006 to 2020
    - Because sub-state geographies aren't included, something would need to be done before combining this data with our ANES data where we have sub-state geographies

## Other Sources

- The General Social Survey
    - excellent temporal coverage for its partisanship variable, going back to 1974
    - Doesn't include state of residence by default
    - Doesn't have a question that parses partisan leaners out of the independent category
    - Applying for restricted data access for geocodes may be an option

- [Nationscape](https://www.voterstudygroup.org/data) data appears to be very promising for geographic coverage, but it only began being collected in 2016.

- [Roper Center for Public Opinion Research's iPoll database](https://ropercenter.cornell.edu/ipoll/) of polls.
    - Many of these are done by news agencies
    - question wordings vary from those in the ANES, and I haven't come across leaners being parsed out anywhere in this database
    - haven't found any surveys that include sub-state geographies

## Polling Data Summary

Polls are sparse and those that are comparable to the ANES are only available for recent years. This is a concern because it limits our ability to increase within-state geographic diversity and decrease missing data at the state level due to some states not being polled in a given year of ANES data. Because we can't add additional data for the earlier half of our time-series where we need it the most, the utility of adding additional polls is limited. Another concern is the overall balance of the data. If we add additional polls for later years we risk artificially inflating their sample sizes and weighting all model estimates towards the means for later years.

## Publicly Available Registration Data

One good source of data would be publicly available registration data, however some states don't report the partisanship of their registered voters, and the data becomes more sparse the further back in time we go. Figure 1 shows the missingness of the registration data by state and year. Each "row" in the graph represents one state in a given year (1988 to 2020). Of course, leaners are not dealt with in this data.

```{r registration-data, fig.width=5, fig.height=5}
# Load swing states data
ss_dat <- rio::import("/home/reed/Dropbox/01-projects/predicting-state-pid/data/swing-states-proj/z_swing-states-output/swing-states-data/swing-states-data_10-aug-2023.csv")

ss_reg_miss <- ss_dat |>
    select(state, year, pct_registered_republican) |>
    arrange(year, state) |>
    select(-year, -state)

p1 <- naniar::vis_miss(select(ss_reg_miss, pct_registered_republican))
p1 + 
    labs(
        title = "Figure 1: Missingness in Registration Data\n sorted by State, then Year") +
    theme_minimal() +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.title.x = element_blank(),
          panel.grid = element_blank(),
          axis.title.y = element_blank()) +
    scale_y_continuous(limits = c(0, nrow(ss_dat)), breaks = seq(48, nrow(ss_dat), by = 48) - 24, labels = as.character(seq(1988, 2020, by = 4)))
```

### Demographic Data

The availability of census-based demographic data also affects the type of partisanship model we can specify because it determines what geographic breakdowns are possible for poststratification. The table below summarizes the census-based data that is available.

```{r}
knitr::kable(read_csv("/home/reed/Dropbox/01-projects/predicting-state-pid/writing/population-data-availability.csv"), caption = "Summary of Census-based Data availability")
```

One joint distribution of demographics and our chosen sub-national geography is needed for each year of estimates. The demographic variables required to generate joint distributions for poststratifying (age, race, sex, educational attainment) are available in the 1980, 1990, and 2000 but not the 2010 or 2020 decennial censuses. This is likely because the American Community Survey (ACS) replaced the long-form census in 2010. Breakdowns of the needed demographics by geographies smaller than the state are available in all of the decennial censuses, and Google Cloud provides complete breakdowns of these demographics by state, county, and census tract from the ACS. Because of the limitations in the census-based data, it seems best to use decennial censuses for the earlier years and the ACS for the years it is available. For earlier years it will be necessary to interpolate new distributions for the years in between the decennial censuses, as @kastellec2015Polarizing did. Interpolation is also needed for the years between 2000 and 2010, where we would have to use the 2000 decennial census and the 2010 ACS. For years falling between 2010 to 2020 we could use the ACS without interpolation because it is available for every year in that range, or interpolate for the sake of consistency.

# Preliminary Results

I have spent some time testing different specifications for the predictive model. The results below are on state-level partisanship using MRP, as well as an estimate using a simple disaggregated mean that was poststratified using the same weights as the other estimates (model 1). The models used to generate these predictions were all fit on a single year of survey data (2012) without including effects for any smaller-order geographies, and were then postsratified to the state level. The baseline specification (model 2) has age, sex, race, and education and interactions between sex and race, educational attainment and age, and educational attainment and race as individual-level predictors. It also includes state random intercepts and region fixed effects. Models 3 and 4 add additional state-level predictors. Each model's specification is summarized in the table below.

| Model | State-level predictors |
|-------|---------------|
| 1     | *Disaggregated mean* |
| 2 (baseline) | State, Region |
| 3     | State, Region, Republican Vote Share in 2012 |
| 4     | State, Region, Republican Vote Share in 2012, Pct. Black, Pct. Urban, Pct. Christian |
:Model Specifications

```{r prep data}
# load MRP results
load("/home/reed/Dropbox/01-projects/predicting-state-pid/data/pid/estimates/mrp-estimates.RData")

# merge mrp and bart results with test data
mrp_results <- mrp_results |>
    left_join(
        all_truth,
        by = c("state", "party")
    ) |>
    mutate(
        abs_error = abs(mean_pid - truth_pid),
        error = mean_pid - truth_pid
    ) |>
    drop_na()
```

**Overall Performance**

```{r overall table, results='asis'}
scores_overall <- mrp_results |>
    group_by(model) |>
    summarize(
        r = cor.test(mean_pid, truth_pid, method = "pearson", conf.level = .95)$estimate,
        "r (conf. low)" = cor.test(mean_pid, truth_pid, method = "pearson", conf.level = .95)$conf.int[1],
        "r (conf. high)" = cor.test(mean_pid, truth_pid, method = "pearson", conf.level = .95)$conf.int[2],
        MAE = mean(abs(mean_pid - truth_pid)),
    ) 

kable(scores_overall)
```

**By Party**

```{r party table, results='asis'}
scores_party <- mrp_results |>
    group_by(model, party) |>
    summarize(
        r = cor.test(mean_pid, truth_pid, method = "pearson", conf.level = .95)$estimate,
        "r (conf. low)" = cor.test(mean_pid, truth_pid, method = "pearson", conf.level = .95)$conf.int[1],
        "r (conf. high)" = cor.test(mean_pid, truth_pid, method = "pearson", conf.level = .95)$conf.int[2],
        MAE = mean(abs(mean_pid - truth_pid)),
    ) 

kable(scores_party)
```

```{r plot 1}
# combine BART with other model results
results <- mrp_results

# get party color palette
load("/home/reed/Dropbox/helpers/party-colors.RData")

# Prep to label outliers

# add abbrs for outlier labels
fips <- read_csv("/home/reed/Dropbox/01-projects/predicting-state-pid/data/helpers/us-state-ansi-fips.csv")
fips <- fips |>
    select(
        state = stname,
        abbr = stusps
    )
results <- results |> 
    left_join(
        fips,
        by = "state"
    )

# outliers function
findoutlier <- function(x) {
  return(x < quantile(x, .25) - 1.5 * IQR(x) | x > quantile(x, .75) + 1.5 * IQR(x))
}

model_perf_by_party <- results |>
    group_by(model, party) |>
    mutate(outlier = ifelse(findoutlier(abs_error), abbr, NA))

# plot
ggplot(model_perf_by_party, aes(x = party, y = abs_error, fill = party)) +
    geom_boxplot() +
    theme_minimal() +
    xlab("Model") +
    ylab("Absolute Error") +
    scale_fill_manual(values = c(party_colors$dem, party_colors$ind, party_colors$rep)) +
    guides(color = guide_legend(title = "Party")) +
    ggrepel::geom_text_repel(aes(label = outlier), na.rm = TRUE, size = 3) +
    facet_grid(~ model) +
    scale_x_discrete(position = "top") +
    theme(axis.text.x = element_blank())
```

## Results Summary

Initial tests in a single year of data show that adding state-level predictors to the model helps with some aspects of predictive accuracy, especially by decreasing the number of states who's true values differ by a large amount from the model's estimates. Unfortunately, many state-level predictors are not available for our entire target time-series, however the results above at least suggest that additional state-level predictors may be useful for improving our estimates. 

Another issue is it seems that if predictive power for each party identification among the model covariates is not balanced then the model will be biased towards predicting the category that is most associated with them. Future work in testing model specification will include testing predictors such as social capital, which could have a stronger association with Independents. Work on modeling "deep interactions" among the demographic variables is also needed. This is a key component of the "deep MRP" approach that has been shown to improve predictive accuracy [@goplerud2023ReEvaluating], but it hasn't been applied to multinomial data.
